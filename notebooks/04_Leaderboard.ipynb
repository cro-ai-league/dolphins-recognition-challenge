{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaderboard\n",
    "\n",
    "> Current leaderboard using validation set. The final leaderboard will be generated at the end of the contest using test dataset and will probably be different due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "in_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "# ignore this\n",
    "in_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "import torch\n",
    "import tempfile\n",
    "\n",
    "from dolphins_recognition_challenge.datasets import get_dataset, get_test_dataset\n",
    "from dolphins_recognition_challenge.instance_segmentation.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def parse_filename(fname):\n",
    "    tmp = fname.split(\"-\")\n",
    "    date = pd.to_datetime(tmp[1] + tmp[2] + tmp[3])\n",
    "    alias = tmp[6]\n",
    "    email = tmp[7]\n",
    "    submitted_iou = tmp[5].split(\"=\")[1]\n",
    "\n",
    "    return {\n",
    "        \"file_name\": fname,\n",
    "        \"date\": date,\n",
    "        \"alias\": alias,\n",
    "        \"email\": email,\n",
    "        \"submitted_iou\": submitted_iou,\n",
    "        \"calculated_iou\": np.nan,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "actual = parse_filename(\n",
    "    \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\"\n",
    ")\n",
    "expected = {\n",
    "    \"file_name\": \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\",\n",
    "    \"date\": pd.to_datetime(\"2020-12-22 15:35:15.513570\"),\n",
    "    \"alias\": \"dolphin123\",\n",
    "    \"email\": \"name.surname@gmail.com\",\n",
    "    \"submitted_iou\": \"0.46613\",\n",
    "    \"calculated_iou\": np.nan,\n",
    "}\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "my_bucket = s3.Bucket(\"ai-league.cisex.org\")\n",
    "private_leaderboard_path = Path(\"private_leaderboard.csv\")\n",
    "public_leaderboard_path = Path(\"leaderboard.csv\")\n",
    "\n",
    "\n",
    "def get_submissions_from_s3(private_leaderboard_path=private_leaderboard_path):\n",
    "    \"\"\"Downloads the zip file from s3 if there is no record of it in the csv file\"\"\"\n",
    "    if private_leaderboard_path.exists():\n",
    "        private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "    else:\n",
    "        private_leaderboard = dict(file_name=[])\n",
    "\n",
    "    # download file into models_for_evaluation directory\n",
    "    s3_objects = [\n",
    "        s3_object\n",
    "        for s3_object in my_bucket.objects.all()\n",
    "        if Path(s3_object.key).match(\"*submission*.zip\")\n",
    "        and Path(s3_object.key).name not in list(private_leaderboard[\"file_name\"])\n",
    "    ]\n",
    "    if len(s3_objects) > 0:\n",
    "        for i, s3_object in enumerate(s3_objects):\n",
    "            print(f\"Downloading {i+1}/{len(s3_objects)} from S3...\")\n",
    "            my_bucket.download_file(s3_object.key, f\"models_for_evaluation/{Path(s3_object.key).name}\")\n",
    "\n",
    "        # return new entries\n",
    "        new_entries = pd.Series([Path(s3_object.key).name for s3_object in s3_objects]).apply(parse_filename).apply(pd.Series)\n",
    "    else:\n",
    "        x = \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\"\n",
    "        new_entries = pd.Series([x]).apply(parse_filename).apply(pd.Series).iloc[:0, :]\n",
    "        \n",
    "    return new_entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def public(private_leaderboard):\n",
    "    return private_leaderboard[[\"alias\", \"date\", \"submitted_iou\", \"calculated_iou\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1/137 from S3...\n",
      "Downloading 2/137 from S3...\n",
      "Downloading 3/137 from S3...\n",
      "Downloading 4/137 from S3...\n",
      "Downloading 5/137 from S3...\n",
      "Downloading 6/137 from S3...\n",
      "Downloading 7/137 from S3...\n",
      "Downloading 8/137 from S3...\n",
      "Downloading 9/137 from S3...\n",
      "Downloading 10/137 from S3...\n",
      "Downloading 11/137 from S3...\n",
      "Downloading 12/137 from S3...\n",
      "Downloading 13/137 from S3...\n",
      "Downloading 14/137 from S3...\n",
      "Downloading 15/137 from S3...\n",
      "Downloading 16/137 from S3...\n",
      "Downloading 17/137 from S3...\n",
      "Downloading 18/137 from S3...\n",
      "Downloading 19/137 from S3...\n",
      "Downloading 20/137 from S3...\n",
      "Downloading 21/137 from S3...\n",
      "Downloading 22/137 from S3...\n",
      "Downloading 23/137 from S3...\n",
      "Downloading 24/137 from S3...\n",
      "Downloading 25/137 from S3...\n",
      "Downloading 26/137 from S3...\n",
      "Downloading 27/137 from S3...\n",
      "Downloading 28/137 from S3...\n",
      "Downloading 29/137 from S3...\n",
      "Downloading 30/137 from S3...\n",
      "Downloading 31/137 from S3...\n",
      "Downloading 32/137 from S3...\n",
      "Downloading 33/137 from S3...\n",
      "Downloading 34/137 from S3...\n",
      "Downloading 35/137 from S3...\n",
      "Downloading 36/137 from S3...\n",
      "Downloading 37/137 from S3...\n",
      "Downloading 38/137 from S3...\n",
      "Downloading 39/137 from S3...\n",
      "Downloading 40/137 from S3...\n",
      "Downloading 41/137 from S3...\n",
      "Downloading 42/137 from S3...\n",
      "Downloading 43/137 from S3...\n",
      "Downloading 44/137 from S3...\n",
      "Downloading 45/137 from S3...\n",
      "Downloading 46/137 from S3...\n",
      "Downloading 47/137 from S3...\n",
      "Downloading 48/137 from S3...\n",
      "Downloading 49/137 from S3...\n",
      "Downloading 50/137 from S3...\n",
      "Downloading 51/137 from S3...\n",
      "Downloading 52/137 from S3...\n",
      "Downloading 53/137 from S3...\n",
      "Downloading 54/137 from S3...\n",
      "Downloading 55/137 from S3...\n",
      "Downloading 56/137 from S3...\n",
      "Downloading 57/137 from S3...\n",
      "Downloading 58/137 from S3...\n",
      "Downloading 59/137 from S3...\n",
      "Downloading 60/137 from S3...\n",
      "Downloading 61/137 from S3...\n",
      "Downloading 62/137 from S3...\n",
      "Downloading 63/137 from S3...\n",
      "Downloading 64/137 from S3...\n",
      "Downloading 65/137 from S3...\n",
      "Downloading 66/137 from S3...\n",
      "Downloading 67/137 from S3...\n",
      "Downloading 68/137 from S3...\n",
      "Downloading 69/137 from S3...\n",
      "Downloading 70/137 from S3...\n",
      "Downloading 71/137 from S3...\n",
      "Downloading 72/137 from S3...\n",
      "Downloading 73/137 from S3...\n",
      "Downloading 74/137 from S3...\n",
      "Downloading 75/137 from S3...\n",
      "Downloading 76/137 from S3...\n",
      "Downloading 77/137 from S3...\n",
      "Downloading 78/137 from S3...\n",
      "Downloading 79/137 from S3...\n",
      "Downloading 80/137 from S3...\n",
      "Downloading 81/137 from S3...\n",
      "Downloading 82/137 from S3...\n",
      "Downloading 83/137 from S3...\n",
      "Downloading 84/137 from S3...\n",
      "Downloading 85/137 from S3...\n",
      "Downloading 86/137 from S3...\n",
      "Downloading 87/137 from S3...\n",
      "Downloading 88/137 from S3...\n",
      "Downloading 89/137 from S3...\n",
      "Downloading 90/137 from S3...\n",
      "Downloading 91/137 from S3...\n",
      "Downloading 92/137 from S3...\n",
      "Downloading 93/137 from S3...\n",
      "Downloading 94/137 from S3...\n",
      "Downloading 95/137 from S3...\n",
      "Downloading 96/137 from S3...\n",
      "Downloading 97/137 from S3...\n",
      "Downloading 98/137 from S3...\n",
      "Downloading 99/137 from S3...\n",
      "Downloading 100/137 from S3...\n",
      "Downloading 101/137 from S3...\n",
      "Downloading 102/137 from S3...\n",
      "Downloading 103/137 from S3...\n",
      "Downloading 104/137 from S3...\n",
      "Downloading 105/137 from S3...\n",
      "Downloading 106/137 from S3...\n",
      "Downloading 107/137 from S3...\n",
      "Downloading 108/137 from S3...\n",
      "Downloading 109/137 from S3...\n",
      "Downloading 110/137 from S3...\n",
      "Downloading 111/137 from S3...\n",
      "Downloading 112/137 from S3...\n",
      "Downloading 113/137 from S3...\n",
      "Downloading 114/137 from S3...\n",
      "Downloading 115/137 from S3...\n",
      "Downloading 116/137 from S3...\n",
      "Downloading 117/137 from S3...\n",
      "Downloading 118/137 from S3...\n",
      "Downloading 119/137 from S3...\n",
      "Downloading 120/137 from S3...\n",
      "Downloading 121/137 from S3...\n",
      "Downloading 122/137 from S3...\n",
      "Downloading 123/137 from S3...\n",
      "Downloading 124/137 from S3...\n",
      "Downloading 125/137 from S3...\n",
      "Downloading 126/137 from S3...\n",
      "Downloading 127/137 from S3...\n",
      "Downloading 128/137 from S3...\n",
      "Downloading 129/137 from S3...\n",
      "Downloading 130/137 from S3...\n",
      "Downloading 131/137 from S3...\n",
      "Downloading 132/137 from S3...\n",
      "Downloading 133/137 from S3...\n",
      "Downloading 134/137 from S3...\n",
      "Downloading 135/137 from S3...\n",
      "Downloading 136/137 from S3...\n",
      "Downloading 137/137 from S3...\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    new_entries = get_submissions_from_s3()\n",
    "    public(new_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "def merge_with_private_leaderboard(\n",
    "    new_entries, private_leaderboard_path=private_leaderboard_path\n",
    "):\n",
    "    # merge private leaderboard and new_entries if needed\n",
    "    new_entries[\"calculated_iou\"] = np.nan\n",
    "    if private_leaderboard_path.exists():\n",
    "        private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "        private_leaderboard = pd.concat([private_leaderboard, new_entries], axis=0)\n",
    "        private_leaderboard = private_leaderboard.drop_duplicates(subset=\"file_name\")\n",
    "    else:\n",
    "        private_leaderboard = new_entries\n",
    "\n",
    "    private_leaderboard.to_csv(private_leaderboard_path, index=False)\n",
    "\n",
    "    return private_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    private_leaderboard = merge_with_private_leaderboard(new_entries)\n",
    "    public(private_leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, mode: str = \"test\") -> float:\n",
    "    # do it\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        with zipfile.ZipFile(model_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=d)\n",
    "            unzipped_path = [x for x in Path(d).glob(\"submiss*\")][0]\n",
    "        \n",
    "        model = torch.load(unzipped_path / \"model.pt\")\n",
    "        if mode.lower() == \"val\":\n",
    "            _, data_loader = get_dataset(\"segmentation\", batch_size=4)\n",
    "        elif mode.lower() == \"test\":\n",
    "            data_loader = get_test_dataset(\"segmentation\", batch_size=4)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        iou, iou_df = iou_metric(model, data_loader.dataset)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    actual = evaluate_model(\n",
    "        Path(\n",
    "            \"models_for_evaluation/uploaded-2021-01-05T15:01:23.563795-submission-iou=0.44003-dolphin123-name.surname@gmail.com-2021-01-05T15:01:21.655750.zip\"\n",
    "        ), mode=\"Val\"\n",
    "    )\n",
    "    expected = 0.44003\n",
    "    np.testing.assert_almost_equal(actual, expected, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 6, 5, 0, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime(2021, 6, 5, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "cut_off_date = datetime.datetime(2021, 6, 5, 0, 0)\n",
    "\n",
    "def evaluate_private_leaderboard(private_leaderboard_path=private_leaderboard_path):\n",
    "    private_leaderboard = pd.read_csv(private_leaderboard_path,parse_dates=[\"date\"])\n",
    "    private_leaderboard = private_leaderboard[private_leaderboard[\"date\"] < cut_off_date]\n",
    "    new_entries = private_leaderboard.loc[private_leaderboard[\"calculated_iou\"].isna()]\n",
    "    \n",
    "    n = new_entries.shape[0]\n",
    "    for i, ix in enumerate(new_entries.index):\n",
    "        row = new_entries.loc[ix]\n",
    "        file_name, alias, dt = row[\"file_name\"], row[\"alias\"], row[\"date\"]\n",
    "        print(f\"Evaluating model {i+1}/{n} for {alias} submitted at {dt}...\")\n",
    "        calculated_iou = evaluate_model(f\"models_for_evaluation/{file_name}\", mode=\"test\")\n",
    "        private_leaderboard.loc[ix, \"calculated_iou\"] = calculated_iou\n",
    "        \n",
    "    private_leaderboard.to_csv(private_leaderboard_path, index=False)\n",
    "    return private_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 1/136 for stokic submitted at 2021-02-21 18:51:53.232539...\n",
      "Evaluating model 2/136 for firstML submitted at 2021-02-28 09:54:54.020979...\n",
      "Evaluating model 3/136 for firstML submitted at 2021-02-28 09:55:59.155951...\n",
      "Evaluating model 4/136 for rangoiv_0.0 submitted at 2021-03-11 21:18:19.755089...\n",
      "Evaluating model 5/136 for testy submitted at 2021-03-12 15:06:14.210987...\n",
      "Evaluating model 6/136 for tekashi submitted at 2021-03-27 12:07:10.438811...\n",
      "Evaluating model 7/136 for dolphinSantiago submitted at 2021-03-28 21:13:52.740719...\n",
      "Evaluating model 8/136 for dupincek submitted at 2021-03-29 17:04:06.266327...\n",
      "Evaluating model 9/136 for Dupin submitted at 2021-03-31 00:17:36.538368...\n",
      "Evaluating model 10/136 for Dupin submitted at 2021-03-31 13:34:11.751663...\n",
      "Evaluating model 11/136 for Dupin submitted at 2021-03-31 14:35:22.171495...\n",
      "Evaluating model 12/136 for tekashi submitted at 2021-03-31 15:40:50.909294...\n",
      "Evaluating model 13/136 for Dupin submitted at 2021-03-31 16:21:11.073692...\n",
      "Evaluating model 14/136 for tekashi submitted at 2021-03-31 16:40:37.163291...\n",
      "Evaluating model 15/136 for Dupin submitted at 2021-03-31 17:54:29.801730...\n",
      "Evaluating model 16/136 for tekashi submitted at 2021-03-31 18:22:29.101320...\n",
      "Evaluating model 17/136 for tekashi submitted at 2021-03-31 18:49:18.357457...\n",
      "Evaluating model 18/136 for tekashi submitted at 2021-03-31 19:20:21.678723...\n",
      "Evaluating model 19/136 for tekashi submitted at 2021-03-31 19:40:13.091625...\n",
      "Evaluating model 20/136 for tekashi submitted at 2021-03-31 19:59:45.495632...\n",
      "Evaluating model 21/136 for tekashi submitted at 2021-03-31 20:16:52.924987...\n",
      "Evaluating model 22/136 for Boto submitted at 2021-03-31 22:30:51.956628...\n",
      "Evaluating model 23/136 for Boto submitted at 2021-03-31 22:54:40.595595...\n",
      "Evaluating model 24/136 for tekashi submitted at 2021-04-01 11:04:15.726242...\n",
      "Evaluating model 25/136 for tekashi submitted at 2021-04-01 11:28:48.148635...\n",
      "Evaluating model 26/136 for tekashi submitted at 2021-04-01 12:10:55.448785...\n",
      "Evaluating model 27/136 for tekashi submitted at 2021-04-01 13:07:48.940732...\n",
      "Evaluating model 28/136 for tekashi submitted at 2021-04-01 14:04:48.589564...\n",
      "Evaluating model 29/136 for tekashi submitted at 2021-04-01 15:01:41.477143...\n",
      "Evaluating model 30/136 for Orka submitted at 2021-04-01 15:06:41.495325...\n",
      "Evaluating model 31/136 for tekashi submitted at 2021-04-01 15:26:55.480008...\n",
      "Evaluating model 32/136 for tekashi submitted at 2021-04-01 15:52:06.237026...\n",
      "Evaluating model 33/136 for tekashi submitted at 2021-04-01 15:58:52.196918...\n",
      "Evaluating model 34/136 for Orka submitted at 2021-04-01 16:05:26.977252...\n",
      "Evaluating model 35/136 for tekashi submitted at 2021-04-01 16:16:48.012391...\n",
      "Evaluating model 36/136 for Orka submitted at 2021-04-01 16:30:39.496708...\n",
      "Evaluating model 37/136 for tekashi submitted at 2021-04-01 16:57:58.374209...\n",
      "Evaluating model 38/136 for tekashi submitted at 2021-04-01 17:57:52.548423...\n",
      "Evaluating model 39/136 for tekashi submitted at 2021-04-01 19:15:19.023312...\n",
      "Evaluating model 40/136 for tekashi submitted at 2021-04-01 19:39:29.095649...\n",
      "Evaluating model 41/136 for Orka submitted at 2021-04-01 22:08:40.180417...\n",
      "Evaluating model 42/136 for Orka submitted at 2021-04-02 01:15:54.079218...\n",
      "Evaluating model 43/136 for Orka submitted at 2021-04-02 16:21:59.548029...\n",
      "Evaluating model 44/136 for tekashi submitted at 2021-04-02 17:24:27.068063...\n",
      "Evaluating model 45/136 for tekashi submitted at 2021-04-02 17:51:50.503276...\n",
      "Evaluating model 46/136 for tekashi submitted at 2021-04-02 18:25:16.310611...\n",
      "Evaluating model 47/136 for tekashi submitted at 2021-04-02 21:19:27.821774...\n",
      "Evaluating model 48/136 for tekashi submitted at 2021-04-07 15:54:44.500487...\n",
      "Evaluating model 49/136 for tekashi submitted at 2021-04-08 13:29:55.225069...\n",
      "Evaluating model 50/136 for tekashi submitted at 2021-04-08 15:29:40.628365...\n",
      "Evaluating model 51/136 for tekashi submitted at 2021-04-08 16:33:59.818491...\n",
      "Evaluating model 52/136 for tekashi submitted at 2021-04-08 19:47:49.222011...\n",
      "Evaluating model 53/136 for tekashi submitted at 2021-04-08 22:25:37.965915...\n",
      "Evaluating model 54/136 for tekashi submitted at 2021-04-08 22:52:30.392290...\n",
      "Evaluating model 55/136 for tekashi submitted at 2021-04-08 23:17:52.200022...\n",
      "Evaluating model 56/136 for tekashi submitted at 2021-04-08 23:43:25.680146...\n",
      "Evaluating model 57/136 for tekashi submitted at 2021-04-09 00:08:46.537238...\n",
      "Evaluating model 58/136 for tekashi submitted at 2021-04-09 00:34:37.672707...\n",
      "Evaluating model 59/136 for tekashi submitted at 2021-04-10 13:58:50.855818...\n",
      "Evaluating model 60/136 for tekashi submitted at 2021-04-10 14:49:17.515990...\n",
      "Evaluating model 61/136 for tekashi submitted at 2021-04-10 15:16:37.928715...\n",
      "Evaluating model 62/136 for tekashi submitted at 2021-04-10 15:42:21.904346...\n",
      "Evaluating model 63/136 for tekashi submitted at 2021-04-10 16:08:17.917942...\n",
      "Evaluating model 64/136 for tekashi submitted at 2021-04-10 16:34:08.413497...\n",
      "Evaluating model 65/136 for tekashi submitted at 2021-04-10 16:59:44.747429...\n",
      "Evaluating model 66/136 for tekashi submitted at 2021-04-10 17:25:25.070860...\n",
      "Evaluating model 67/136 for tekashi submitted at 2021-04-11 21:40:41.667352...\n",
      "Evaluating model 68/136 for tekashi submitted at 2021-04-11 22:35:50.476177...\n",
      "Evaluating model 69/136 for tekashi submitted at 2021-04-15 18:43:52.761958...\n",
      "Evaluating model 70/136 for tekashi submitted at 2021-04-15 19:50:42.676767...\n",
      "Evaluating model 71/136 for tekashi submitted at 2021-04-15 20:15:34.477416...\n",
      "Evaluating model 72/136 for tekashi submitted at 2021-04-15 20:40:46.415186...\n",
      "Evaluating model 73/136 for tekashi submitted at 2021-04-16 11:55:28.934231...\n",
      "Evaluating model 74/136 for tekashi submitted at 2021-04-16 12:19:34.306772...\n",
      "Evaluating model 75/136 for tekashi submitted at 2021-04-16 12:51:01.534622...\n",
      "Evaluating model 76/136 for tekashi submitted at 2021-04-16 14:09:10.298425...\n",
      "Evaluating model 77/136 for tekashi submitted at 2021-04-16 14:33:55.678166...\n",
      "Evaluating model 78/136 for tekashi submitted at 2021-04-19 13:31:48.969477...\n",
      "Evaluating model 79/136 for tekashi submitted at 2021-04-19 14:08:15.473097...\n",
      "Evaluating model 80/136 for tekashi submitted at 2021-04-19 14:37:39.983910...\n",
      "Evaluating model 81/136 for tekashi submitted at 2021-04-19 15:03:11.966772...\n",
      "Evaluating model 82/136 for tekashi submitted at 2021-04-20 15:38:21.826060...\n",
      "Evaluating model 83/136 for tekashi submitted at 2021-04-20 16:32:55.400389...\n",
      "Evaluating model 84/136 for tekashi submitted at 2021-04-20 17:14:30.635349...\n",
      "Evaluating model 85/136 for tekashi submitted at 2021-04-20 18:07:11.087187...\n",
      "Evaluating model 86/136 for tekashi submitted at 2021-04-20 18:33:05.351845...\n",
      "Evaluating model 87/136 for tekashi submitted at 2021-04-20 19:02:09.744250...\n",
      "Evaluating model 88/136 for tekashi submitted at 2021-04-20 19:31:43.024354...\n",
      "Evaluating model 89/136 for tekashi submitted at 2021-04-22 11:17:10.649215...\n",
      "Evaluating model 90/136 for tekashi submitted at 2021-04-22 12:55:04.012067...\n",
      "Evaluating model 91/136 for tekashi submitted at 2021-04-22 13:57:05.651327...\n",
      "Evaluating model 92/136 for tekashi submitted at 2021-04-22 14:48:50.634662...\n",
      "Evaluating model 93/136 for tekashi submitted at 2021-04-22 15:51:05.155017...\n",
      "Evaluating model 94/136 for tekashi submitted at 2021-04-22 16:43:07.921596...\n",
      "Evaluating model 95/136 for tekashi submitted at 2021-04-22 17:32:33.525988...\n",
      "Evaluating model 96/136 for alias submitted at 2021-05-01 18:26:52.200870...\n",
      "Evaluating model 97/136 for dolphin_rovinj submitted at 2021-05-01 20:06:35.372099...\n",
      "Evaluating model 98/136 for alias submitted at 2021-05-02 10:38:49.415151...\n",
      "Evaluating model 99/136 for alias submitted at 2021-05-25 11:22:23.408031...\n",
      "Evaluating model 100/136 for assert0 submitted at 2021-05-30 17:16:46.563665...\n",
      "Evaluating model 101/136 for Fico submitted at 2021-06-02 13:18:06.353793...\n",
      "Evaluating model 102/136 for Fico submitted at 2021-06-02 16:55:13.328466...\n",
      "Evaluating model 103/136 for dolphinn submitted at 2021-06-02 22:27:42.318280...\n",
      "Evaluating model 104/136 for dolphinn submitted at 2021-06-02 22:53:56.469456...\n",
      "Evaluating model 105/136 for dolphinn submitted at 2021-06-02 23:25:59.245905...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 106/136 for duplin submitted at 2021-06-03 09:59:18.678395...\n",
      "Evaluating model 107/136 for AquamanZo submitted at 2021-06-03 17:04:02.918431...\n",
      "Evaluating model 108/136 for AquamanZo submitted at 2021-06-03 17:04:34.739131...\n",
      "Evaluating model 109/136 for AquamanZo submitted at 2021-06-03 17:05:06.111293...\n",
      "Evaluating model 110/136 for AquamanZo submitted at 2021-06-03 17:05:55.772358...\n",
      "Evaluating model 111/136 for AquamanZo submitted at 2021-06-03 19:32:37.145129...\n",
      "Evaluating model 112/136 for AquamanZo submitted at 2021-06-03 20:27:38.962213...\n",
      "Evaluating model 113/136 for assert0 submitted at 2021-06-03 21:40:16.765718...\n",
      "Evaluating model 114/136 for assert0 submitted at 2021-06-03 21:54:44.044253...\n",
      "Evaluating model 115/136 for assert0 submitted at 2021-06-03 22:00:20.069381...\n",
      "Evaluating model 116/136 for duplin submitted at 2021-06-03 23:51:45.089378...\n",
      "Evaluating model 117/136 for assert0 submitted at 2021-06-04 08:37:00.543298...\n",
      "Evaluating model 118/136 for assert0 submitted at 2021-06-04 10:00:09.374985...\n",
      "Evaluating model 119/136 for assert0 submitted at 2021-06-04 10:30:20.820612...\n",
      "Evaluating model 120/136 for alias1 submitted at 2021-06-04 10:45:15.451028...\n",
      "Evaluating model 121/136 for assert0 submitted at 2021-06-04 11:44:48.333133...\n",
      "Evaluating model 122/136 for assert0 submitted at 2021-06-04 12:29:38.374120...\n",
      "Evaluating model 123/136 for alias submitted at 2021-06-04 13:05:31.930730...\n",
      "Evaluating model 124/136 for alias submitted at 2021-06-04 13:12:47.567693...\n",
      "Evaluating model 125/136 for dolphinn submitted at 2021-06-04 13:22:35.965824...\n",
      "Evaluating model 126/136 for assert0 submitted at 2021-06-04 14:30:21.417518...\n",
      "Evaluating model 127/136 for assert0 submitted at 2021-06-04 15:02:18.362307...\n",
      "Evaluating model 128/136 for assert0 submitted at 2021-06-04 16:12:22.433067...\n",
      "Evaluating model 129/136 for assert0 submitted at 2021-06-04 16:45:57.706187...\n",
      "Evaluating model 130/136 for assert0 submitted at 2021-06-04 16:57:15.270782...\n",
      "Evaluating model 131/136 for assert0 submitted at 2021-06-04 17:16:49.346124...\n",
      "Evaluating model 132/136 for assert0 submitted at 2021-06-04 17:38:58.575539...\n",
      "Evaluating model 133/136 for alias submitted at 2021-06-04 18:01:00.038300...\n",
      "Evaluating model 134/136 for dolphinn submitted at 2021-06-04 19:37:13.319690...\n",
      "Evaluating model 135/136 for dolphinn submitted at 2021-06-04 20:35:15.664234...\n",
      "Evaluating model 136/136 for test1 submitted at 2021-06-04 20:53:40.681073...\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    evaluate_private_leaderboard()\n",
    "    private_leaderboard = pd.read_csv(\"private_leaderboard.csv\")\n",
    "    assert not private_leaderboard[\"calculated_iou\"].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def save_public_leaderboard(private_leaderboard_path=private_leaderboard_path, public_leaderboard_path=public_leaderboard_path):\n",
    "    private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "    public_leaderboard = public(private_leaderboard)\n",
    "    public_leaderboard.to_csv(public_leaderboard_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    save_public_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_leaderboard(public_leaderboard_path=public_leaderboard_path):\n",
    "    public_leaderboard = pd.read_csv(public_leaderboard_path)\n",
    "    public_leaderboard = public_leaderboard[\n",
    "        (public_leaderboard.alias != \"dolphin123\")\n",
    "        & (public_leaderboard.alias != \"malimedo\")\n",
    "        & (public_leaderboard.alias != \"prvi_pokušaj\")\n",
    "    ]\n",
    "    public_leaderboard = public_leaderboard.sort_values(\n",
    "        by=[\"calculated_iou\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "    public_leaderboard.drop_duplicates(subset=\"alias\", keep=\"first\", inplace=True)\n",
    "\n",
    "    public_leaderboard = public_leaderboard.sort_values(\n",
    "        by=[\"calculated_iou\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "    public_leaderboard.index = public_leaderboard.index + 1\n",
    "    return public_leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a temporary leaderboard calculated daily using validation data. The final leaderboard will be calculated using test dataset unavailable to participants and will most likely be different than the one provided here due to overfitting on the validation dataset. Please see the following link for the details: https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>date</th>\n",
       "      <th>submitted_iou</th>\n",
       "      <th>calculated_iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquamanZo</td>\n",
       "      <td>2021-06-03 17:05:55.772358</td>\n",
       "      <td>0.51072</td>\n",
       "      <td>0.516741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tekashi</td>\n",
       "      <td>2021-04-20 19:31:43.024354</td>\n",
       "      <td>0.50132</td>\n",
       "      <td>0.513168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolphinSantiago</td>\n",
       "      <td>2021-03-28 21:13:52.740719</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.490305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alias</td>\n",
       "      <td>2021-06-04 13:05:31.930730</td>\n",
       "      <td>0.57413</td>\n",
       "      <td>0.487422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alias1</td>\n",
       "      <td>2021-06-04 10:45:15.451028</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.473954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>duplin</td>\n",
       "      <td>2021-06-03 09:59:18.678395</td>\n",
       "      <td>0.46366</td>\n",
       "      <td>0.471571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fico</td>\n",
       "      <td>2021-06-02 13:18:06.353793</td>\n",
       "      <td>0.46946</td>\n",
       "      <td>0.468637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Orka</td>\n",
       "      <td>2021-04-02 16:21:59.548029</td>\n",
       "      <td>0.47683</td>\n",
       "      <td>0.467433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boto</td>\n",
       "      <td>2021-03-31 22:30:51.956628</td>\n",
       "      <td>0.44334</td>\n",
       "      <td>0.461158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dupin</td>\n",
       "      <td>2021-03-31 14:35:22.171495</td>\n",
       "      <td>0.46228</td>\n",
       "      <td>0.457796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dolphin_rovinj</td>\n",
       "      <td>2021-05-01 20:06:35.372099</td>\n",
       "      <td>0.43487</td>\n",
       "      <td>0.457270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dolphinn</td>\n",
       "      <td>2021-06-02 23:25:59.245905</td>\n",
       "      <td>0.45828</td>\n",
       "      <td>0.456409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>assert0</td>\n",
       "      <td>2021-05-30 17:16:46.563665</td>\n",
       "      <td>0.44340</td>\n",
       "      <td>0.455922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test1</td>\n",
       "      <td>2021-06-04 20:53:40.681073</td>\n",
       "      <td>0.44507</td>\n",
       "      <td>0.451674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dupincek</td>\n",
       "      <td>2021-03-29 17:04:06.266327</td>\n",
       "      <td>0.44912</td>\n",
       "      <td>0.446151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stokic</td>\n",
       "      <td>2021-02-21 18:51:53.232539</td>\n",
       "      <td>0.43552</td>\n",
       "      <td>0.442665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>firstML</td>\n",
       "      <td>2021-02-28 09:54:54.020979</td>\n",
       "      <td>0.42529</td>\n",
       "      <td>0.432354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rangoiv_0.0</td>\n",
       "      <td>2021-03-11 21:18:19.755089</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.426023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>testy</td>\n",
       "      <td>2021-03-12 15:06:14.210987</td>\n",
       "      <td>0.39001</td>\n",
       "      <td>0.372717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              alias                        date  submitted_iou  calculated_iou\n",
       "1         AquamanZo  2021-06-03 17:05:55.772358        0.51072        0.516741\n",
       "2           tekashi  2021-04-20 19:31:43.024354        0.50132        0.513168\n",
       "3   dolphinSantiago  2021-03-28 21:13:52.740719        0.48156        0.490305\n",
       "4             alias  2021-06-04 13:05:31.930730        0.57413        0.487422\n",
       "5            alias1  2021-06-04 10:45:15.451028        0.57750        0.473954\n",
       "6            duplin  2021-06-03 09:59:18.678395        0.46366        0.471571\n",
       "7              Fico  2021-06-02 13:18:06.353793        0.46946        0.468637\n",
       "8              Orka  2021-04-02 16:21:59.548029        0.47683        0.467433\n",
       "9              Boto  2021-03-31 22:30:51.956628        0.44334        0.461158\n",
       "10            Dupin  2021-03-31 14:35:22.171495        0.46228        0.457796\n",
       "11   dolphin_rovinj  2021-05-01 20:06:35.372099        0.43487        0.457270\n",
       "12         dolphinn  2021-06-02 23:25:59.245905        0.45828        0.456409\n",
       "13          assert0  2021-05-30 17:16:46.563665        0.44340        0.455922\n",
       "14            test1  2021-06-04 20:53:40.681073        0.44507        0.451674\n",
       "15         dupincek  2021-03-29 17:04:06.266327        0.44912        0.446151\n",
       "16           stokic  2021-02-21 18:51:53.232539        0.43552        0.442665\n",
       "17          firstML  2021-02-28 09:54:54.020979        0.42529        0.432354\n",
       "18      rangoiv_0.0  2021-03-11 21:18:19.755089        0.41769        0.426023\n",
       "19            testy  2021-03-12 15:06:14.210987        0.39001        0.372717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "\n",
    "if not in_test:\n",
    "    display(get_leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('leaderboard.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "public_leaderboard_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
