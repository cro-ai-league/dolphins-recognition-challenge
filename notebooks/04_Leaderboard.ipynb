{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaderboard\n",
    "\n",
    "> Current leaderboard using validation set. The final leaderboard will be generated at the end of the contest using test dataset and will probably be different due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "in_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "# ignore this\n",
    "in_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "import torch\n",
    "import tempfile\n",
    "\n",
    "from dolphins_recognition_challenge.datasets import get_dataset\n",
    "from dolphins_recognition_challenge.instance_segmentation.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "\n",
    "def parse_filename(fname):\n",
    "    tmp = fname.split(\"-\")\n",
    "    date = pd.to_datetime(tmp[1] + tmp[2] + tmp[3])\n",
    "    alias = tmp[6]\n",
    "    email = tmp[7]\n",
    "    submitted_iou = tmp[5].split(\"=\")[1]\n",
    "\n",
    "    return {\n",
    "        \"file_name\": fname,\n",
    "        \"date\": date,\n",
    "        \"alias\": alias,\n",
    "        \"email\": email,\n",
    "        \"submitted_iou\": submitted_iou,\n",
    "        \"calculated_iou\": np.nan,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "actual = parse_filename(\n",
    "    \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\"\n",
    ")\n",
    "expected = {\n",
    "    \"file_name\": \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\",\n",
    "    \"date\": pd.to_datetime(\"2020-12-22 15:35:15.513570\"),\n",
    "    \"alias\": \"dolphin123\",\n",
    "    \"email\": \"name.surname@gmail.com\",\n",
    "    \"submitted_iou\": \"0.46613\",\n",
    "    \"calculated_iou\": np.nan,\n",
    "}\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "my_bucket = s3.Bucket(\"ai-league.cisex.org\")\n",
    "private_leaderboard_path = Path(\"private_leaderboard.csv\")\n",
    "public_leaderboard_path = Path(\"leaderboard.csv\")\n",
    "\n",
    "\n",
    "def get_submissions_from_s3(private_leaderboard_path=private_leaderboard_path):\n",
    "    \"\"\"Downloads the zip file from s3 if there is no record of it in the csv file\"\"\"\n",
    "    if private_leaderboard_path.exists():\n",
    "        private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "    else:\n",
    "        private_leaderboard = dict(file_name=[])\n",
    "\n",
    "    # download file into models_for_evaluation directory\n",
    "    s3_objects = [\n",
    "        s3_object\n",
    "        for s3_object in my_bucket.objects.all()\n",
    "        if Path(s3_object.key).match(\"*submission*.zip\")\n",
    "        and Path(s3_object.key).name not in list(private_leaderboard[\"file_name\"])\n",
    "    ]\n",
    "    if len(s3_objects) > 0:\n",
    "        for i, s3_object in enumerate(s3_objects):\n",
    "            print(f\"Downloading {i+1}/{len(s3_objects)} from S3...\")\n",
    "            my_bucket.download_file(s3_object.key, f\"models_for_evaluation/{Path(s3_object.key).name}\")\n",
    "\n",
    "        # return new entries\n",
    "        new_entries = pd.Series([Path(s3_object.key).name for s3_object in s3_objects]).apply(parse_filename).apply(pd.Series)\n",
    "    else:\n",
    "        x = \"uploaded-2020-12-22T15:35:15.513570-submission-iou=0.46613-dolphin123-name.surname@gmail.com-2020-12-22T15:35:04.875962.zip\"\n",
    "        new_entries = pd.Series([x]).apply(parse_filename).apply(pd.Series).iloc[:0, :]\n",
    "        \n",
    "    return new_entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def public(private_leaderboard):\n",
    "    return private_leaderboard[[\"alias\", \"date\", \"submitted_iou\", \"calculated_iou\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    new_entries = get_submissions_from_s3()\n",
    "    public(new_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "def merge_with_private_leaderboard(\n",
    "    new_entries, private_leaderboard_path=private_leaderboard_path\n",
    "):\n",
    "    # merge private leaderboard and new_entries if needed\n",
    "    new_entries[\"calculated_iou\"] = np.nan\n",
    "    if private_leaderboard_path.exists():\n",
    "        private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "        private_leaderboard = pd.concat([private_leaderboard, new_entries], axis=0)\n",
    "        private_leaderboard = private_leaderboard.drop_duplicates(subset=\"file_name\")\n",
    "    else:\n",
    "        private_leaderboard = new_entries\n",
    "\n",
    "    private_leaderboard.to_csv(private_leaderboard_path, index=False)\n",
    "\n",
    "    return private_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    private_leaderboard = merge_with_private_leaderboard(new_entries)\n",
    "    public(private_leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def evaluate_model(model_path) -> float:\n",
    "    # do it\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        with zipfile.ZipFile(model_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=d)\n",
    "            unzipped_path = [x for x in Path(d).glob(\"submiss*\")][0]\n",
    "\n",
    "        model = torch.load(unzipped_path / \"model.pt\")\n",
    "        data_loader, data_loader_test = get_dataset(\"segmentation\", batch_size=4)\n",
    "        iou, iou_df = iou_metric(model, data_loader_test.dataset)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RegionProposalNetwork' object has no attribute 'score_thresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a4e66a04aeae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     actual = evaluate_model(\n\u001b[0m\u001b[1;32m      5\u001b[0m         Path(\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m\"models_for_evaluation/uploaded-2021-01-05T15:01:23.563795-submission-iou=0.44003-dolphin123-name.surname@gmail.com-2021-01-05T15:01:21.655750.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-20afac67cb38>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munzipped_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"segmentation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/airt/dolphins_recognition_challenge/instance_segmentation/model.py\u001b[0m in \u001b[0;36miou_metric\u001b[0;34m(model, dataset, score_threshold)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34m\"\"\"Calculate IOU metric on the whole dataloader\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     iou = [\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0miou_metric_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/airt/dolphins_recognition_challenge/instance_segmentation/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     iou = [\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0miou_metric_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     ]\n",
      "\u001b[0;32m/tf/airt/dolphins_recognition_challenge/instance_segmentation/model.py\u001b[0m in \u001b[0;36miou_metric_example\u001b[0;34m(model, example, score_threshold)\u001b[0m\n\u001b[1;32m    313\u001b[0m ) -> float:\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0miou_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou_metric_matrix_of_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0mmatching_ious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlargest_values_in_row_colums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_ious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/airt/dolphins_recognition_challenge/instance_segmentation/model.py\u001b[0m in \u001b[0;36miou_metric_matrix_of_example\u001b[0;34m(model, example, score_threshold)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mscore_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m ) -> List[List[float]]:\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_true_and_predicted_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     return np.array(\n",
      "\u001b[0;32m/tf/airt/dolphins_recognition_challenge/instance_segmentation/model.py\u001b[0m in \u001b[0;36mget_true_and_predicted_masks\u001b[0;34m(model, example, score_threshold)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mpred_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_bbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors_per_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mfilter_proposals\u001b[0;34m(self, proposals, objectness, image_shapes, num_anchors_per_level)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;31m# remove low scoring boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m# use >= for Backwards compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RegionProposalNetwork' object has no attribute 'score_thresh'"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    actual = evaluate_model(\n",
    "        Path(\n",
    "            \"models_for_evaluation/uploaded-2021-01-05T15:01:23.563795-submission-iou=0.44003-dolphin123-name.surname@gmail.com-2021-01-05T15:01:21.655750.zip\"\n",
    "        )\n",
    "    )\n",
    "    expected = 0.44003\n",
    "    np.testing.assert_almost_equal(actual, expected, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def evaluate_private_leaderboard(private_leaderboard_path=private_leaderboard_path):\n",
    "    private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "    new_entries = private_leaderboard.loc[private_leaderboard[\"calculated_iou\"].isna()]\n",
    "    \n",
    "    n = new_entries.shape[0]\n",
    "    for i, ix in enumerate(new_entries.index):\n",
    "        row = new_entries.loc[ix]\n",
    "        file_name, alias, dt = row[\"file_name\"], row[\"alias\"], row[\"date\"]\n",
    "        print(f\"Evaluating model {i+1}/{n} for {alias} submitted at {dt}...\")\n",
    "        calculated_iou = evaluate_model(f\"models_for_evaluation/{file_name}\")\n",
    "        private_leaderboard.loc[ix, \"calculated_iou\"] = calculated_iou\n",
    "        \n",
    "    private_leaderboard.to_csv(private_leaderboard_path, index=False)\n",
    "    return private_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    private_leaderboard = pd.read_csv(\"private_leaderboard.csv\")\n",
    "    assert np.nan not in list(private_leaderboard[\"calculated_iou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def save_public_leaderboard(private_leaderboard_path=private_leaderboard_path, public_leaderboard_path=public_leaderboard_path):\n",
    "    private_leaderboard = pd.read_csv(private_leaderboard_path)\n",
    "    public_leaderboard = public(private_leaderboard)\n",
    "    public_leaderboard.to_csv(public_leaderboard_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not in_test:\n",
    "    save_public_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_leaderboard(public_leaderboard_path=public_leaderboard_path):\n",
    "    public_leaderboard = pd.read_csv(public_leaderboard_path)\n",
    "    public_leaderboard = public_leaderboard[\n",
    "        (public_leaderboard.alias != \"dolphin123\")\n",
    "        & (public_leaderboard.alias != \"malimedo\")\n",
    "        & (public_leaderboard.alias != \"prvi_poku≈°aj\")\n",
    "    ]\n",
    "    public_leaderboard = public_leaderboard.sort_values(\n",
    "        by=[\"submitted_iou\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "    public_leaderboard.drop_duplicates(subset=\"alias\", keep=\"first\", inplace=True)\n",
    "\n",
    "    public_leaderboard = public_leaderboard.sort_values(\n",
    "        by=[\"submitted_iou\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "    public_leaderboard.index = public_leaderboard.index + 1\n",
    "    return public_leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a temporary leaderboard calculated daily using validation data. The final leaderboard will be calculated using test dataset unavailable to participants and will most likely be different than the one provided here due to overfitting on the validation dataset. Please see the following link for the details: https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>date</th>\n",
       "      <th>submitted_iou</th>\n",
       "      <th>calculated_iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tekashi</td>\n",
       "      <td>2021-04-19 15:03:11.966772</td>\n",
       "      <td>0.51546</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dolphinSantiago</td>\n",
       "      <td>2021-03-28 21:13:52.740719</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orka</td>\n",
       "      <td>2021-04-02 16:21:59.548029</td>\n",
       "      <td>0.47683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alias</td>\n",
       "      <td>2021-05-02 10:38:49.415151</td>\n",
       "      <td>0.46234</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dupin</td>\n",
       "      <td>2021-03-31 14:35:22.171495</td>\n",
       "      <td>0.46228</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dupincek</td>\n",
       "      <td>2021-03-29 17:04:06.266327</td>\n",
       "      <td>0.44912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boto</td>\n",
       "      <td>2021-03-31 22:54:40.595595</td>\n",
       "      <td>0.44678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stokic</td>\n",
       "      <td>2021-02-21 18:51:53.232539</td>\n",
       "      <td>0.43552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dolphin_rovinj</td>\n",
       "      <td>2021-05-01 20:06:35.372099</td>\n",
       "      <td>0.43487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>firstML</td>\n",
       "      <td>2021-02-28 09:55:59.155951</td>\n",
       "      <td>0.42529</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rangoiv_0.0</td>\n",
       "      <td>2021-03-11 21:18:19.755089</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>testy</td>\n",
       "      <td>2021-03-12 15:06:14.210987</td>\n",
       "      <td>0.39001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              alias                        date  submitted_iou  calculated_iou\n",
       "1           tekashi  2021-04-19 15:03:11.966772        0.51546             NaN\n",
       "2   dolphinSantiago  2021-03-28 21:13:52.740719        0.48156             NaN\n",
       "3              Orka  2021-04-02 16:21:59.548029        0.47683             NaN\n",
       "4             alias  2021-05-02 10:38:49.415151        0.46234             NaN\n",
       "5             Dupin  2021-03-31 14:35:22.171495        0.46228             NaN\n",
       "6          dupincek  2021-03-29 17:04:06.266327        0.44912             NaN\n",
       "7              Boto  2021-03-31 22:54:40.595595        0.44678             NaN\n",
       "8            stokic  2021-02-21 18:51:53.232539        0.43552             NaN\n",
       "9    dolphin_rovinj  2021-05-01 20:06:35.372099        0.43487             NaN\n",
       "10          firstML  2021-02-28 09:55:59.155951        0.42529             NaN\n",
       "11      rangoiv_0.0  2021-03-11 21:18:19.755089        0.41769             NaN\n",
       "12            testy  2021-03-12 15:06:14.210987        0.39001             NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "\n",
    "if not in_test:\n",
    "    display(get_leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('leaderboard.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "public_leaderboard_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
